{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Introduction to Artificial Neural Nerworks - Part 1/3\n","\n","### Welcome to this short tutorial!\n","The general idea of this series is to build an Artificial Neural Network from scratch starting with its fundamental unit, the Perceptron, and then slowly add elements until we can build and use a pretrained Neural Network ready to apply to complex tasks. During the process we'll explain each stage as accessibly as possible.\n","\n","It is a long topic, so we'll be dividing it in smaller parts to make it easier to handle.\n","\n","What you need to know before starting:\n"," - Basic Python programming skills\n"," - Basic knowledge of linear algebra\n","\n","Now, let's begin!"]},{"cell_type":"markdown","metadata":{},"source":["## Imports"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"S0cH4e9ljfYG"},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import random\n","plt.rcParams['figure.dpi'] = 100\n","sns.set_style('darkgrid')"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[],"source":["random.seed(66)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"OmrKoUI-bTNL"},"source":["## **Perceptron**\n","\n","*Rosenblatt's perceptron (1962)* is a **binary classification algorithm** that takes an input vector, process it, and generates a single output through an non linear **activation function** called \"step function.\"\n","\n"," - Each input is a number and is associated with a *weight*.\n","\n"," - There is usually a *bias* (or constant) term.\n","\n"," - A *weighted sum* is performed on all of these elements and then passed through a step function that will return a *binary output*, 1 or 0 (or sometimes +1 and -1, depends on the author).\n","\n","In the following image you can see a representation of the elements mentioned above.\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["<img src=\"images/perceptron-6168423.png\" width=\"600\">\n"]},{"cell_type":"markdown","metadata":{},"source":["### Step Function\n","\n","A step function is one type of activation function. In the following tutorials we will talk about other types. But the main takeaway is that activation functions perform nonlinlear transformations allowing the algorithm to generate a more versatile output.\n"," \n","We define the step function as following:\n","\n","\\begin{equation}\n","f(z) = \n","\\begin{cases}\n","    1 & \\text{if }~~ z >= 0 \\\\\n","    0 & \\text{if }~~ z < 0\n","\\end{cases}\n","\\end{equation}\n","\n","Which means that the output will be 1 if the input is larger or equal to 0, and 0 if the input is smaller than 0.\n","\n","Now let's move to the fun part and write the code for this function and plot it."]},{"cell_type":"code","execution_count":23,"metadata":{"id":"P2AMnFtHbXCk"},"outputs":[],"source":["def step_function(z: float) -> float:\n","  # Returns the output of the step function for a given number\n","  return 1.0 if z >= 0 else 0.0"]},{"cell_type":"markdown","metadata":{},"source":["Let's check if it works"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["0.0\n","1.0\n"]}],"source":["print(step_function(-0.5))\n","print(step_function(0.5))"]},{"cell_type":"markdown","metadata":{},"source":["Awesome! Seems to be returning exactly what we needed.\n","\n","Now we can try to plot it with some more points to actually see how this function behaves."]},{"cell_type":"markdown","metadata":{},"source":["We generate an array of 25 values within the range -0.5 and 0.5."]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[-0.5        -0.45833333 -0.41666667 -0.375      -0.33333333 -0.29166667\n"," -0.25       -0.20833333 -0.16666667 -0.125      -0.08333333 -0.04166667\n","  0.          0.04166667  0.08333333  0.125       0.16666667  0.20833333\n","  0.25        0.29166667  0.33333333  0.375       0.41666667  0.45833333\n","  0.5       ]\n"]}],"source":["y = np.linspace(-0.5, 0.5, 25)\n","print(y)"]},{"cell_type":"markdown","metadata":{},"source":["We pass each of those values through our step function."]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n"," 1.]\n"]}],"source":["s = np.array([step_function(i) for i in y])\n","print(s)"]},{"cell_type":"markdown","metadata":{},"source":["And plot those two arrays together."]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 400x300 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["plt.figure(figsize=(4,3))\n","plt.title(\"Homemade step function\")\n","plt.plot(y, s, color=\"green\")\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["I hope that now it's clear *why* it's called \"step function\".\n","\n","We can clearly see that it does what we expected: it assigns 0 to every value under 0 and 1 to every value over 0.\n","\n","This is how this function *classifies* stuff; the magic behind the perceptron and the basis of ANN. Based on the input values, it creates a non-linearity that chooses one class or the other."]},{"cell_type":"markdown","metadata":{},"source":["### Defining a perceptron function"]},{"cell_type":"markdown","metadata":{},"source":["Having our step function ready to go, we can define the perceptron itself.\n","\n","It shoud take an array of inputs and weights, perform a dot product betweent them, add the bias and, finally, return the step function to its output.\n","\n","Let's write the code.\n"]},{"cell_type":"code","execution_count":28,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1676305496432,"user":{"displayName":"Julieta Millán","userId":"14594503620603826162"},"user_tz":180},"id":"5YQR3FMLjtno","outputId":"440e11c0-db1a-479d-a80f-dfe8e4371aed"},"outputs":[],"source":["def perceptron(inputs: np.array, weights: np.array, bias: float) -> float:\n","  # Performs the dot product of inputs and weights, adds bias\n","  # Returns step function of the total\n","  total = np.dot(weights, inputs) + bias\n","  return step_function(total)"]},{"cell_type":"markdown","metadata":{},"source":["We choose some inputs and weights to pass to our perceptron.\n","\n","The inputs would be the real data from our dataset and the weights are normally initialized with small random numbers or zeroes."]},{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[],"source":["inputs = np.array([2, 1, 0.5])       # x1 = 2, x2 = 3\n","weights = np.array([0.1, 0.2, 0.1]) # w1 = 0, w2 = 1\n","bias = 1"]},{"cell_type":"markdown","metadata":{},"source":["And, finally, pass all of these elements to the perceptron function we defined above and get its class \"prediction\"."]},{"cell_type":"code","execution_count":30,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["The inputs correspond to class: 1.0\n"]}],"source":["print(\"The inputs correspond to class:\", perceptron(inputs, weights, bias))    # 1.0"]},{"cell_type":"markdown","metadata":{},"source":["Try it out generating random numbers for inputs and weights and see if the prediction changes!"]},{"cell_type":"code","execution_count":31,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[ 4 -2  2  3]\n","[[0.42594472 0.68170372 0.92845514 0.64431231]]\n","The inputs correspond to class: 1.0\n"]}],"source":["inputs = np.random.randint(-5, 5, 4)\n","print(inputs)\n","weights = np.random.rand(1, 4)\n","print(weights)\n","\n","print(\"The inputs correspond to class:\", perceptron(inputs, weights, bias))"]},{"cell_type":"markdown","metadata":{},"source":["### Defining a \"Neuron\"\n","\n","So far we have defined a couple of functions that, together, make a basic algorithm. \n","\n","As the next step we should write a python class named \"Neuron\" that:\n"," - Initializes with the weights and bias\n"," - Takes inputs that go through a **feedforward** method (the same a the Perceptron algorithm that we defined above)\n"," - The feedforward method performs the **dot product** and returns the output of the **step function**"]},{"cell_type":"code","execution_count":32,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1676305496432,"user":{"displayName":"Julieta Millán","userId":"14594503620603826162"},"user_tz":180},"id":"I5SRsC9bjNhO","outputId":"9144da69-efb4-477b-b674-04fb98c901df"},"outputs":[],"source":["class Neuron:\n","  def __init__(self, weights, bias):\n","    self.weights = weights\n","    self.bias = bias\n","\n","  def step_function(self, z):\n","    return 1.0 if z >= 0 else 0.0\n","\n","  def feedforward(self, inputs):\n","    total = np.dot(self.weights, inputs) + self.bias\n","    return step_function(total)"]},{"cell_type":"code","execution_count":33,"metadata":{},"outputs":[],"source":["inputs = np.array([2, 1, 0.5])       # x1 = 2, x2 = 3\n","weights = np.array([0.1, 0.2, 0.1]) # w1 = 0, w2 = 1\n","bias = 1"]},{"cell_type":"code","execution_count":34,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Prediction for Neuron:  1.0\n"]}],"source":["neuron = Neuron(weights, bias)\n","print(\"Prediction for Neuron: \", neuron.feedforward(inputs))  "]},{"cell_type":"markdown","metadata":{},"source":["Again, we can test it with random values to see how the prediction varies."]},{"cell_type":"code","execution_count":35,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[-5 -5 -3  0]\n","[[0.07716416 0.58521324 0.64902357 0.35017802]]\n","Prediction for Neuron:  0.0\n"]}],"source":["inputs = np.random.randint(-5, 5, 4)\n","print(inputs)\n","weights = np.random.rand(1, 4)\n","print(weights)\n","\n","neuron = Neuron(weights, bias)\n","print(\"Prediction for Neuron: \", neuron.feedforward(inputs))  "]},{"cell_type":"markdown","metadata":{},"source":["## **Multilayer Perceptron**\n","\n","Due to its simple nature, a single Perceptron algorithm only works with linearly separable data.\n","\n","<img src=\"images/Linearly_Separable_Data_Example.webp\">\n","\n","To tackle this problem, we can combine perceptrons (neurons) assembling them into networks. \n","\n","The simplest architecture of an Artificial Neural Network is a Multilayer Perceptron, where each layer's output is the input of the following layer, and all of the nodes (neurons) of one layer are connected to all the neurons of the following one. This is also known as a fully connected or dense layer; we'll talk more about them in the following tutorials.\n","\n","\n","\n","<img src=\"images/multilayer_perceptron.png\" width=\"500\">\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["\n","We create a neural network (combination of perceptrones) with:\n"," - two inputs\n"," - one hidden layer with two neurons (h1, h2)\n"," - one output layer with one neuron (o1)\n"," \n","Each Neuron has the same weights and biases:\n"," - w = [0, 1]\n"," - b = 0\n"]},{"cell_type":"code","execution_count":36,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":258,"status":"ok","timestamp":1676305709281,"user":{"displayName":"Julieta Millán","userId":"14594503620603826162"},"user_tz":180},"id":"Rd5BfpDoaO2y","outputId":"a6e11dd4-6342-4c84-8dbe-280b30a91e4d"},"outputs":[],"source":["class MultilayerPerceptron():\n","\n","  def __init__(self):\n","    weights = np.array([0, 1])\n","    bias = 0\n","\n","    # The Neuron class that we define above\n","    self.h1 = Neuron(weights, bias)\n","    self.h2 = Neuron(weights, bias)\n","    self.o1 = Neuron(weights, bias)\n","\n","  def feedforward(self, x):\n","    out_h1 = self.h1.feedforward(x)\n","    out_h2 = self.h2.feedforward(x)\n","\n","    # The inputs for o1 are the outputs of h1 and h2\n","    out_o1 = self.o1.feedforward(np.array([out_h1, out_h2]))\n","\n","    return out_o1\n"]},{"cell_type":"markdown","metadata":{},"source":["It's important to clarify that this might not be the best way to write this function; it is done this way for clarity regarding the architecture of the network.\n","\n","Also, if we need to use a neural network for a real-world problem, we will never write it from scratch by ourselves; we will use saved models or pretrained networks. We will work with this kind of algorithms in the following tutorials."]},{"cell_type":"code","execution_count":37,"metadata":{},"outputs":[],"source":["network = MultilayerPerceptron()"]},{"cell_type":"code","execution_count":42,"metadata":{},"outputs":[],"source":["inputs = np.array([2, 3])"]},{"cell_type":"code","execution_count":43,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["The prediction of the network is:  1.0\n"]}],"source":["print(\"The prediction of the network is: \", network.feedforward(inputs))"]},{"cell_type":"markdown","metadata":{},"source":["## Training\n","\n","So far we have defined the most basic structure of a neural network but, did our algorithm learn anything? Not yet! \n","\n","The network we made was not trained, we just passed inputs and asked the network what it thought, but we never checked if the answers were correct.\n","\n","For this next step, the training of the network, we should define a loss function (error between prediction and real value).\n","\n","*Training* itself means that the network should minimize its loss function by finding the best weights through multiple iterations of feedforward and **backpropagation**.\n","\n","We use a method called Gradient Descent to optimise weights and biases that minimise the loss function.\n","\n","<img src=\"images/backpropagation.avif\" width=\"500\">\n","\n","Even though the details of the Gradient Descent method go beyond the scope of this tutorial, I recommend [StaQuest's video about it](https://www.youtube.com/watch?v=sDv4f4s2SB8&ab_channel=StatQuestwithJoshStarmer) if you are interested to understand how it works."]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"c6KhaUF3m2DV"},"source":["### Bibliography\n","\n","Géron, A. (2019). Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow, 2nd Edition. O'Reilly Media, Inc.\n","\n","Bishop, C. (2006). Patter Recognition and Machine Learning. Springer New York, NY.\n","\n","Nielsen, M. (2015), Neural Networks and Deep Learning, Determination Press.\n","\n","StatQuest Gradient Descent: https://www.youtube.com/watch?v=sDv4f4s2SB8\n","\n","Verma, S. (April, 2021), Implementing the Perceptron Algorithm in Python. Towards Data Science. https://towardsdatascience.com/perceptron-algorithm-in-python-f3ac89d2e537\n","\n","Zhou, V. (March, 2019), Machine Learning for Beginners: An Introduction to Neural Networks, Towards Data Science. https://towardsdatascience.com/machine-learning-for-beginners-an-introduction-to-neural-networks-d49f22d238f9\n","\n","Bento, C. (September 2021), Multilayer Perceptron Explained with a Real-Life Example and Python Code: Sentiment Analysis, Towards Data Science. https://towardsdatascience.com/multilayer-perceptron-explained-with-a-real-life-example-and-python-code-sentiment-analysis-cb408ee93141\n"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyPM4NAg2HgIQAipY0PFSrVU","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.7"}},"nbformat":4,"nbformat_minor":0}
